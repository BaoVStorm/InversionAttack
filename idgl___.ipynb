{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import LFWPeople\n",
    "import pickle\n",
    "import PIL.Image as Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, channel=3, hideen=768, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channel, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=1),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hideen, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    try:\n",
    "        if hasattr(m, \"weight\"):\n",
    "            m.weight.data.uniform_(-0.5, 0.5)\n",
    "    except Exception:\n",
    "        print('warning: failed in weights_init for %s.weight' % m._get_name())\n",
    "    try:\n",
    "        if hasattr(m, \"bias\"):\n",
    "            m.bias.data.uniform_(-0.5, 0.5)\n",
    "    except Exception:\n",
    "        print('warning: failed in weights_init for %s.bias' % m._get_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_from_Image(Dataset):\n",
    "    def __init__(self, imgs, labs, transform=None):\n",
    "        self.imgs = imgs # img paths\n",
    "        self.labs = labs # labs is ndarray\n",
    "        self.transform = transform\n",
    "        del imgs, labs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labs.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lab = self.labs[idx]\n",
    "        img = Image.open(self.imgs[idx])\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        return img, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST root_path: .\n",
      "MNIST data_path: ./MNIST/.\n",
      "MNIST save_path: ./results/iDLG_MNIST\n",
      "running 0|1000 experiment\n",
      "DLG, Try to generate 1 images\n",
      "lr = 1.0\n",
      "[2024-11-21 18:13:04] 0 loss = 47.62801361, mse = 4.95444822\n",
      "[2024-11-21 18:13:11] 10 loss = 0.00054432, mse = 0.00034014\n",
      "[2024-11-21 18:13:19] 20 loss = 0.00009325, mse = 0.00008449\n",
      "[2024-11-21 18:13:26] 30 loss = 0.00006034, mse = 0.00003430\n",
      "[2024-11-21 18:13:33] 40 loss = 0.00004096, mse = 0.00001678\n",
      "[2024-11-21 18:13:40] 50 loss = 0.00002727, mse = 0.00000790\n",
      "[2024-11-21 18:13:49] 60 loss = 0.00001886, mse = 0.00000358\n",
      "[2024-11-21 18:13:56] 70 loss = 0.00001356, mse = 0.00000243\n",
      "[2024-11-21 18:14:04] 80 loss = 0.00001340, mse = 0.00000186\n",
      "[2024-11-21 18:14:12] 90 loss = 0.00001497, mse = 0.00000146\n",
      "[2024-11-21 18:14:19] 100 loss = 0.00000952, mse = 0.00000121\n",
      "[2024-11-21 18:14:27] 110 loss = 0.00000959, mse = 0.00000100\n",
      "[2024-11-21 18:14:36] 120 loss = 0.00000966, mse = 0.00000091\n",
      "[2024-11-21 18:14:45] 130 loss = 0.00001312, mse = 0.00000081\n",
      "[2024-11-21 18:14:54] 140 loss = 0.00000818, mse = 0.00000076\n",
      "[2024-11-21 18:15:01] 150 loss = 0.00001490, mse = 0.00000073\n",
      "[2024-11-21 18:15:08] 160 loss = 0.00000693, mse = 0.00000068\n",
      "[2024-11-21 18:15:16] 170 loss = 0.00001284, mse = 0.00000063\n",
      "[2024-11-21 18:15:24] 180 loss = 0.00000765, mse = 0.00000060\n",
      "[2024-11-21 18:15:32] 190 loss = 0.00000707, mse = 0.00000057\n",
      "[2024-11-21 18:15:40] 200 loss = 0.00000657, mse = 0.00000055\n",
      "[2024-11-21 18:15:47] 210 loss = 0.00000562, mse = 0.00000054\n",
      "[2024-11-21 18:15:55] 220 loss = 0.00000619, mse = 0.00000053\n",
      "[2024-11-21 18:16:04] 230 loss = 0.00001096, mse = 0.00000052\n",
      "[2024-11-21 18:16:12] 240 loss = 0.00000778, mse = 0.00000050\n",
      "[2024-11-21 18:16:20] 250 loss = 0.00000573, mse = 0.00000049\n",
      "[2024-11-21 18:16:30] 260 loss = 0.00000723, mse = 0.00000049\n",
      "[2024-11-21 18:16:40] 270 loss = 0.00000769, mse = 0.00000048\n",
      "[2024-11-21 18:16:47] 280 loss = 0.00000891, mse = 0.00000046\n",
      "[2024-11-21 18:16:51] 290 loss = 708.67449951, mse = 88289240.00000000\n",
      "iDLG, Try to generate 1 images\n",
      "lr = 1.0\n",
      "[2024-11-21 18:16:52] 0 loss = 6.66009521, mse = 0.44483534\n",
      "[2024-11-21 18:16:58] 10 loss = 0.00017068, mse = 0.00013310\n",
      "[2024-11-21 18:17:05] 20 loss = 0.00005824, mse = 0.00005083\n",
      "[2024-11-21 18:17:12] 30 loss = 0.00004356, mse = 0.00003279\n",
      "[2024-11-21 18:17:19] 40 loss = 0.00003194, mse = 0.00002109\n",
      "[2024-11-21 18:17:26] 50 loss = 0.00005020, mse = 0.00001430\n",
      "[2024-11-21 18:17:33] 60 loss = 0.00002142, mse = 0.00001002\n",
      "[2024-11-21 18:17:40] 70 loss = 0.00002306, mse = 0.00000551\n",
      "[2024-11-21 18:17:47] 80 loss = 0.00001377, mse = 0.00000341\n",
      "[2024-11-21 18:17:55] 90 loss = 0.00001114, mse = 0.00000264\n",
      "[2024-11-21 18:18:02] 100 loss = 0.00001286, mse = 0.00000207\n",
      "[2024-11-21 18:18:10] 110 loss = 0.00001853, mse = 0.00000175\n",
      "[2024-11-21 18:18:17] 120 loss = 0.00000934, mse = 0.00000151\n",
      "[2024-11-21 18:18:25] 130 loss = 0.00001239, mse = 0.00000136\n",
      "[2024-11-21 18:18:32] 140 loss = 0.00003619, mse = 0.00000117\n",
      "[2024-11-21 18:18:40] 150 loss = 0.00000864, mse = 0.00000126\n",
      "[2024-11-21 18:18:47] 160 loss = 0.00000875, mse = 0.00000115\n",
      "[2024-11-21 18:18:55] 170 loss = 0.00000686, mse = 0.00000109\n",
      "[2024-11-21 18:19:03] 180 loss = 0.00001351, mse = 0.00000108\n",
      "[2024-11-21 18:19:11] 190 loss = 0.00000881, mse = 0.00000105\n",
      "[2024-11-21 18:19:18] 200 loss = 0.00001604, mse = 0.00000101\n",
      "[2024-11-21 18:19:26] 210 loss = 0.00000692, mse = 0.00000097\n",
      "[2024-11-21 18:19:33] 220 loss = 0.00000991, mse = 0.00000095\n",
      "[2024-11-21 18:19:41] 230 loss = 0.00001076, mse = 0.00000094\n",
      "[2024-11-21 18:19:51] 240 loss = 0.00000907, mse = 0.00000091\n",
      "[2024-11-21 18:19:59] 250 loss = 0.00000795, mse = 0.00000089\n",
      "[2024-11-21 18:20:08] 260 loss = 0.00000819, mse = 0.00000087\n",
      "[2024-11-21 18:20:18] 270 loss = 0.00000758, mse = 0.00000085\n",
      "[2024-11-21 18:20:26] 280 loss = 0.00000901, mse = 0.00000084\n",
      "[2024-11-21 18:20:35] 290 loss = 0.00001271, mse = 0.00000081\n",
      "imidx_list: [38004]\n",
      "loss_DLG: 708.6744995117188 loss_iDLG: 5.344371402316028e-06\n",
      "mse_DLG: 88289240.0 mse_iDLG: 7.988319907781261e-07\n",
      "gt_label: [7] lab_DLG: 8 lab_iDLG: 7\n",
      "----------------------\n",
      "\n",
      "\n",
      "running 1|1000 experiment\n",
      "DLG, Try to generate 1 images\n",
      "lr = 1.0\n",
      "[2024-11-21 18:20:43] 0 loss = 20.23925972, mse = 0.67369032\n",
      "[2024-11-21 18:20:49] 10 loss = 0.00068092, mse = 0.00009419\n",
      "[2024-11-21 18:20:56] 20 loss = 0.00024753, mse = 0.00002664\n",
      "[2024-11-21 18:21:03] 30 loss = 0.00015292, mse = 0.00001934\n",
      "[2024-11-21 18:21:09] 40 loss = 0.00009899, mse = 0.00001345\n",
      "[2024-11-21 18:21:16] 50 loss = 0.00007302, mse = 0.00001319\n",
      "[2024-11-21 18:21:23] 60 loss = 0.00006198, mse = 0.00001230\n",
      "[2024-11-21 18:21:31] 70 loss = 0.00005448, mse = 0.00001136\n",
      "[2024-11-21 18:21:38] 80 loss = 0.00005472, mse = 0.00001028\n",
      "[2024-11-21 18:21:45] 90 loss = 0.00004640, mse = 0.00000926\n",
      "[2024-11-21 18:21:51] 100 loss = 0.00004584, mse = 0.00000872\n",
      "[2024-11-21 18:21:59] 110 loss = 0.00004301, mse = 0.00000815\n",
      "[2024-11-21 18:22:06] 120 loss = 0.00004310, mse = 0.00000749\n",
      "[2024-11-21 18:22:13] 130 loss = 0.00004145, mse = 0.00000705\n",
      "[2024-11-21 18:22:21] 140 loss = 0.00003536, mse = 0.00000639\n",
      "[2024-11-21 18:22:29] 150 loss = 0.00003310, mse = 0.00000586\n",
      "[2024-11-21 18:22:38] 160 loss = 0.00004664, mse = 0.00000508\n",
      "[2024-11-21 18:22:46] 170 loss = 0.00003349, mse = 0.00000515\n",
      "[2024-11-21 18:22:55] 180 loss = 0.00003332, mse = 0.00000484\n",
      "[2024-11-21 18:23:02] 190 loss = 0.00003383, mse = 0.00000447\n",
      "[2024-11-21 18:23:10] 200 loss = 0.00003088, mse = 0.00000404\n",
      "[2024-11-21 18:23:18] 210 loss = 0.00003714, mse = 0.00000382\n",
      "[2024-11-21 18:23:25] 220 loss = 0.00003837, mse = 0.00000367\n",
      "[2024-11-21 18:23:33] 230 loss = 0.00002882, mse = 0.00000354\n",
      "[2024-11-21 18:23:40] 240 loss = 0.00003222, mse = 0.00000346\n",
      "[2024-11-21 18:23:48] 250 loss = 0.00003011, mse = 0.00000339\n",
      "[2024-11-21 18:23:56] 260 loss = 0.00003122, mse = 0.00000334\n",
      "[2024-11-21 18:24:05] 270 loss = 0.00003425, mse = 0.00000327\n",
      "[2024-11-21 18:24:15] 280 loss = 0.00003086, mse = 0.00000324\n",
      "[2024-11-21 18:24:24] 290 loss = 0.00002931, mse = 0.00000321\n",
      "iDLG, Try to generate 1 images\n",
      "lr = 1.0\n",
      "[2024-11-21 18:24:34] 0 loss = 298.15130615, mse = 3.19289994\n",
      "[2024-11-21 18:24:40] 10 loss = 140.86860657, mse = 145.12969971\n",
      "[2024-11-21 18:24:47] 20 loss = 123.80238342, mse = 166.45042419\n",
      "[2024-11-21 18:24:54] 30 loss = 111.93186951, mse = 187.71363831\n",
      "[2024-11-21 18:25:03] 40 loss = 106.10927582, mse = 211.75988770\n",
      "[2024-11-21 18:25:11] 50 loss = 101.66403198, mse = 234.05850220\n",
      "[2024-11-21 18:25:19] 60 loss = 98.43035889, mse = 264.45605469\n",
      "[2024-11-21 18:25:26] 70 loss = 95.22526550, mse = 291.14016724\n",
      "[2024-11-21 18:25:33] 80 loss = 46.90108490, mse = 310.09091187\n",
      "[2024-11-21 18:25:40] 90 loss = 42.74490738, mse = 333.22409058\n"
     ]
    }
   ],
   "source": [
    "def main(dataset):\n",
    "    root_path = '.'\n",
    "    data_path = os.path.join(root_path).replace('\\\\', '/')\n",
    "    save_path = os.path.join(root_path, 'results/iDLG_%s'%dataset).replace('\\\\', '/')\n",
    "    \n",
    "    lr = 1.0\n",
    "    num_dummy = 1\n",
    "    Iteration = 300\n",
    "    num_exp = 1000\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = 'cuda' if use_cuda else 'cpu'\n",
    "\n",
    "    tt = transforms.Compose([transforms.ToTensor()])\n",
    "    tp = transforms.Compose([transforms.ToPILImage()])\n",
    "\n",
    "    print(dataset, 'root_path:', root_path)\n",
    "    print(dataset, 'data_path:', data_path)\n",
    "    print(dataset, 'save_path:', save_path)\n",
    "\n",
    "    if not os.path.exists('results'):\n",
    "        os.mkdir('results')\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path)\n",
    "\n",
    "    # channel = 0\n",
    "    # shape_img = (0, 0)\n",
    "    # num_classes = 0\n",
    "    # channel = 0\n",
    "    # hidden = 0\n",
    "    # dst = 0\n",
    "\n",
    "    ''' load data '''\n",
    "    if dataset == 'MNIST':\n",
    "        shape_img = (28, 28)\n",
    "        num_classes = 10\n",
    "        channel = 1\n",
    "        hidden = 588\n",
    "        dst = datasets.MNIST(root=\"MNIST/.\", download=False)\n",
    "\n",
    "    elif dataset == 'CIFAR100':\n",
    "        shape_img = (32, 32)\n",
    "        num_classes = 100\n",
    "        channel = 3\n",
    "        hidden = 768\n",
    "        dst = datasets.CIFAR100(root=\"CIFAR100/.\", download=False)\n",
    "\n",
    "    elif dataset == 'LFW':\n",
    "        shape_img = (62, 47)\n",
    "        num_classes = len(set(dataset.targets))\n",
    "        channel = 3\n",
    "        hidden = 768\n",
    "        dst = datasets.LFWPeople(root=\"LFW/.\", download=False)\n",
    "\n",
    "    else:\n",
    "        exit('unknown dataset')\n",
    "\n",
    "\n",
    "    ''' train DLG and iDLG '''\n",
    "    for idx_net in range(num_exp):\n",
    "        net = LeNet(channel=channel, hideen=hidden, num_classes=num_classes)\n",
    "        net.apply(weights_init)\n",
    "\n",
    "        print('running %d|%d experiment'%(idx_net, num_exp))\n",
    "        net = net.to(device)\n",
    "        idx_shuffle = np.random.permutation(len(dst))\n",
    "\n",
    "        for method in ['DLG', 'iDLG']:\n",
    "            print('%s, Try to generate %d images' % (method, num_dummy))\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss().to(device)\n",
    "            imidx_list = []\n",
    "\n",
    "            for imidx in range(num_dummy):\n",
    "                idx = idx_shuffle[imidx]\n",
    "                imidx_list.append(idx)\n",
    "                tmp_datum = tt(dst[idx][0]).float().to(device)\n",
    "                tmp_datum = tmp_datum.view(1, *tmp_datum.size())\n",
    "                tmp_label = torch.Tensor([dst[idx][1]]).long().to(device)\n",
    "                tmp_label = tmp_label.view(1, )\n",
    "                if imidx == 0:\n",
    "                    gt_data = tmp_datum\n",
    "                    gt_label = tmp_label\n",
    "                else:\n",
    "                    gt_data = torch.cat((gt_data, tmp_datum), dim=0)\n",
    "                    gt_label = torch.cat((gt_label, tmp_label), dim=0)\n",
    "\n",
    "\n",
    "            # compute original gradient\n",
    "            out = net(gt_data)\n",
    "            y = criterion(out, gt_label)\n",
    "            dy_dx = torch.autograd.grad(y, net.parameters())\n",
    "            original_dy_dx = list((_.detach().clone() for _ in dy_dx))\n",
    "\n",
    "            # generate dummy data and label\n",
    "            dummy_data = torch.randn(gt_data.size()).to(device).requires_grad_(True)\n",
    "            dummy_label = torch.randn((gt_data.shape[0], num_classes)).to(device).requires_grad_(True)\n",
    "\n",
    "            if method == 'DLG':\n",
    "                optimizer = torch.optim.LBFGS([dummy_data, dummy_label], lr=lr)\n",
    "            elif method == 'iDLG':\n",
    "                optimizer = torch.optim.LBFGS([dummy_data, ], lr=lr)\n",
    "                # predict the ground-truth label\n",
    "                label_pred = torch.argmin(torch.sum(original_dy_dx[-2], dim=-1), dim=-1).detach().reshape((1,)).requires_grad_(False)\n",
    "\n",
    "            history = []\n",
    "            history_iters = []\n",
    "            losses = []\n",
    "            mses = []\n",
    "            train_iters = []\n",
    "\n",
    "            print('lr =', lr)\n",
    "            for iters in range(Iteration):\n",
    "\n",
    "                def closure():\n",
    "                    optimizer.zero_grad()\n",
    "                    pred = net(dummy_data)\n",
    "                    if method == 'DLG':\n",
    "                        dummy_loss = - torch.mean(torch.sum(torch.softmax(dummy_label, -1) * torch.log(torch.softmax(pred, -1)), dim=-1))\n",
    "                        # dummy_loss = criterion(pred, gt_label)\n",
    "                    elif method == 'iDLG':\n",
    "                        dummy_loss = criterion(pred, label_pred)\n",
    "\n",
    "                    dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
    "\n",
    "                    grad_diff = 0\n",
    "                    for gx, gy in zip(dummy_dy_dx, original_dy_dx):\n",
    "                        grad_diff += ((gx - gy) ** 2).sum()\n",
    "                    grad_diff.backward()\n",
    "                    return grad_diff\n",
    "\n",
    "                optimizer.step(closure)\n",
    "                current_loss = closure().item()\n",
    "                train_iters.append(iters)\n",
    "                losses.append(current_loss)\n",
    "                mses.append(torch.mean((dummy_data-gt_data)**2).item())\n",
    "\n",
    "\n",
    "                if iters % int(Iteration / 30) == 0:\n",
    "                    current_time = str(time.strftime(\"[%Y-%m-%d %H:%M:%S]\", time.localtime()))\n",
    "                    print(current_time, iters, 'loss = %.8f, mse = %.8f' %(current_loss, mses[-1]))\n",
    "                    history.append([tp(dummy_data[imidx].cpu()) for imidx in range(num_dummy)])\n",
    "                    history_iters.append(iters)\n",
    "\n",
    "                    for imidx in range(num_dummy):\n",
    "                        plt.figure(figsize=(12, 8))\n",
    "                        plt.subplot(3, 10, 1)\n",
    "                        plt.imshow(tp(gt_data[imidx].cpu()))\n",
    "                        for i in range(min(len(history), 29)):\n",
    "                            plt.subplot(3, 10, i + 2)\n",
    "                            plt.imshow(history[i][imidx])\n",
    "                            plt.title('iter=%d' % (history_iters[i]))\n",
    "                            plt.axis('off')\n",
    "                        if method == 'DLG':\n",
    "                            plt.savefig('%s/DLG_on_%s_%05d.png' % (save_path, imidx_list, imidx_list[imidx]))\n",
    "                            plt.close()\n",
    "                        elif method == 'iDLG':\n",
    "                            plt.savefig('%s/iDLG_on_%s_%05d.png' % (save_path, imidx_list, imidx_list[imidx]))\n",
    "                            plt.close()\n",
    "\n",
    "                    if current_loss < 0.000001: # converge\n",
    "                        break\n",
    "\n",
    "            if method == 'DLG':\n",
    "                loss_DLG = losses\n",
    "                label_DLG = torch.argmax(dummy_label, dim=-1).detach().item()\n",
    "                mse_DLG = mses\n",
    "            elif method == 'iDLG':\n",
    "                loss_iDLG = losses\n",
    "                label_iDLG = label_pred.item()\n",
    "                mse_iDLG = mses\n",
    "\n",
    "\n",
    "\n",
    "        print('imidx_list:', imidx_list)\n",
    "        print('loss_DLG:', loss_DLG[-1], 'loss_iDLG:', loss_iDLG[-1])\n",
    "        print('mse_DLG:', mse_DLG[-1], 'mse_iDLG:', mse_iDLG[-1])\n",
    "        print('gt_label:', gt_label.detach().cpu().data.numpy(), 'lab_DLG:', label_DLG, 'lab_iDLG:', label_iDLG)\n",
    "\n",
    "        print('----------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    for dataset in [\"MNIST\", \"CIFAR100\", \"LFW\"]:    \n",
    "        main(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
